{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import feature_selection\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement: Our data is from the 1912 titanic disaster. We want to find out if we can use certain characteristics of each passenger on the boat to determine survival. On a larger scale. we want to find out if we can develop a model that can be beneficial for emergency management in light of a disaster.  More specifically, can we use a passsengers boarding pass information to determine if that they survived a plane crash?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Aquire the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Connect to the remote database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/Lola/anaconda/lib/python2.7/site-packages/psycopg2/_psycopg.so, 2): Library not loaded: libssl.1.0.0.dylib\n  Referenced from: /Users/Lola/anaconda/lib/python2.7/site-packages/psycopg2/_psycopg.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-23eb1e1e208d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconnect_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com:5432/titanic'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnect_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Lola/anaconda/lib/python2.7/site-packages/sqlalchemy/engine/__init__.pyc\u001b[0m in \u001b[0;36mcreate_engine\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'strategy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Lola/anaconda/lib/python2.7/site-packages/sqlalchemy/engine/strategies.pyc\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, name_or_url, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0mdbapi_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpop_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mdbapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdialect_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdbapi_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mdialect_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dbapi'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Lola/anaconda/lib/python2.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.pyc\u001b[0m in \u001b[0;36mdbapi\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Lola/anaconda/lib/python2.7/site-packages/psycopg2/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Import the DBAPI-2.0 stuff into top-level module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_psycopg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBINARY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUMBER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTRING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATETIME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mROWID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_psycopg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/Lola/anaconda/lib/python2.7/site-packages/psycopg2/_psycopg.so, 2): Library not loaded: libssl.1.0.0.dylib\n  Referenced from: /Users/Lola/anaconda/lib/python2.7/site-packages/psycopg2/_psycopg.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "#use \"conda install psycopg2\" on terminal\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "connect_param = 'postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com:5432/titanic'\n",
    "engine = create_engine(connect_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"train\", engine)\n",
    "df.head()\n",
    "del df[\"index\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptions of the variables are provided below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable|Description|Data Type|Variable Type\n",
    "--|--|--\n",
    "PassengerId|Unique ID for each passenger|Integer|Discrete\n",
    "Survived|Survival (0 = No; 1 = Yes)|Integer|Binary\n",
    "Pclass|Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)|Integer|Categorical Ordinal\n",
    "Name|Passenger's name|Object|Unique\n",
    "Sex|Passenger's sex|Object|Categorical\n",
    "Age|Passenger's age|Float|Continuous\n",
    "SibSp|Number of siblings/spouses on board|Integer|Categorical Ordinal\n",
    "Parch|Number of parents/children on board|Integer|Categorical Ordinal\n",
    "Ticket|Ticket number|Object|Unique\n",
    "Fare|Passenger fare|Float|Continuous\n",
    "Cabin|Passenger's cabin|Object|Categorical Non-Ordinal\n",
    "Embarked|Port of embarkment (C = Cherbourg; Q = Queenstown; S=Southampton)|Object|Categorical Non-Ordinal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame consists of 891 entries and 12 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heat map provides relationships between variables in the dataframe. From the map, we that class is negatively correlated to survival while Fare is postively correlated. This is makes sense intuitively because poeple from Classes 2 and 3 payed less fares and were less likely to survive - the rich people first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"Pclass\", y=\"Age\", hue=\"Survived\", data=df, palette=\"muted\", figsize=(18, 6), split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the first violinplot, we see the distibution of age across classes for both those that survived and those that didn't. In class 1, people that survied were, on average, younger than people that didn't. In classes 2 and 3, we see that the avergae of those that survived was similar to that of those that didn't. Also, there more children in classes 2 and 3, and most of them survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=df, split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows a distribution of of males and females that survived across the three classes. There are several things to observe from this plot. First, survival rate is lower in classes 2 and 3. Women in all classes survived more that men. More women survived than didn't in classes 1 and 2. Very few womene in classes 1 and 2 died. It appears to be the case that the proportion of women that survived in class 3 is similar to that of women that didn't survive in class 3. Finally, the lower the class the more men that died."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"Embarked\", y=\"Survived\", hue=\"Sex\", data=df, split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last plot shows a distribution of males and females that survival based on their port of embarkment. Fewer men from Queentown survived and fewer women from Queesntown died. In general, more women survived than men, and more men died than women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#How many missing Age values are there?\n",
    "sum(df[\"Age\"].isnull().values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#How is it distributed?\n",
    "df.Age.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We see that the distribtution is mainly centered around the mean(and there are few outliers). \n",
    "#For this reason, I will replace the empty fields with the overall mean age.\n",
    "age_pipe = make_pipeline(Imputer(strategy=\"mean\"))\n",
    "df[\"Age\"] = pd.DataFrame(age_pipe.fit_transform(df[[\"Age\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#How many missing fields are in the \"Embarked\" column?\n",
    "sum(df[\"Embarked\"].isnull().values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A large proportion of the passengers embarked from Southampton. \n",
    "#Since we only have only twp empty fields in \"Embarked\" column, I will replace them with the majority i.e. Southampton.\n",
    "df.Embarked = df.Embarked.fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isnull().any()\n",
    "#I will not be using the \"Cabin\" column so I would worry about it's missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I want to create dummy variables for Sex, Embarked, and Pclass.\n",
    "#Since I won't be needing it anymore, I dropped the \"Sex\" column in df2.\n",
    "dummydf = pd.get_dummies(df[\"Sex\"])\n",
    "dummydf2 = pd.get_dummies(df[\"Embarked\"])\n",
    "dummydf3 = pd.get_dummies(df[\"Pclass\"], prefix =\"Class\")\n",
    "df2 = df[[\"Survived\", \"Pclass\", \"Age\", \"SibSp\", \"Parch\", \n",
    "          \"Fare\", \"Embarked\"]].join(dummydf)\n",
    "df3 = df2[df2.columns].join(dummydf2)\n",
    "df4 = df3[df3.columns].join(dummydf3)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To decide which columns to delete, I want to see which values are most frequent.\n",
    "#I will be using the original dataframe (df) for this.\n",
    "print df.Sex.value_counts()\n",
    "print df.Embarked.value_counts()\n",
    "print df.Pclass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I also want to drop the \"Embarked\" and \"Pclass\" columns.\n",
    "df4.drop(df4[[\"Pclass\", \"Embarked\", \"male\", \"S\", \"Class_3\"]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I want to make \"Age\" values integers instead of columns (It makes more sense that way).\n",
    "df4[[\"Age\"]] = df4[[\"Age\"]].astype(int)\n",
    "df4.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df4.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap show correlations between the variables we will be using in the regression. From the graph, we see that being female is the most positively related to survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Logistic Regression and Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I want to define the variables for my regression analysis.\n",
    "#My dependent variable (y) is the \"Survived\" column.\n",
    "#My independent variables (x) are \"Age\", \"Parch\", \"SibSp\", \"Fare\", \"Female\", \"C\", \"Q\", \"Class_1\", and \"Class_2\".\n",
    "X = df4[df4.columns[1:]]\n",
    "y = df4[df4.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The regression.\n",
    "lm = LogisticRegression()\n",
    "\n",
    "result = lm.fit(X,y)\n",
    "predictions = lm.predict(X)\n",
    "print \"Score:\",result.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To determine the coefficients for the correlations and the intercept:\n",
    "print result.coef_\n",
    "print result.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To determine the p-value for each coefficient:\n",
    "from sklearn.feature_selection import chi2\n",
    "scores, pvalues = chi2(X, y)\n",
    "pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To determine the odds for each coefficeient, I have to take the exponent of the coefficient.\n",
    "#The same goes for the intercept.\n",
    "print np.exp(result.coef_)\n",
    "print np.exp(result.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable|Coefficient|P-Value\n",
    "--|--|--\n",
    "Age|0.962|0.000\n",
    "SibSp|0.723|0.108\n",
    "Parch|0.907|0.001\n",
    "Fare|1.003|0.000\n",
    "female|13.261|0.000\n",
    "C|1.490|0.000\n",
    "Q|1.360|0.917\n",
    "Class_1|6.859|0.000\n",
    "Class_2|2.955|0.013\n",
    "Intercept|0.336|-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our results, we see that all coefficients but SibSp and Q are statistically signifant at a 5% significance level. Age, SibSp and Parch generally decrease the odds of survival while Fare, Female, C, Q, Class_1, and Class_2 generally increase the odds of survival. For this model, our baseline is a male from Southhampton in the 3rd class. This person has a 0.34 to 1 odds of survival. If this person happened to be female, their odds of survival increases to 4.46 to 1 (13.261 x 0.336). If this person were to be female and in the 1st class (keeping other factors the same), their odds increases to 30.59 to 1 (13.261 x 0.336 x 6.859).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I want group the age into bins to see which age group impacted survival the most. \n",
    "def binAge(age): \n",
    "    if age > 60:\n",
    "        return \"61 and above\"\n",
    "    elif age >= 46:\n",
    "        return \"46-60\"\n",
    "    elif age >= 31:\n",
    "        return \"31-45\"\n",
    "    elif age >= 16:\n",
    "        return \"16-30\"\n",
    "    \n",
    "    return \"16 and under\"\n",
    "df4[\"Age\"] = df4.Age.map(lambda age: binAge(age) )\n",
    "df5 = df4\n",
    "dummies5 = pd.get_dummies( df5[\"Age\"], prefix = \"Age\" )\n",
    "newData = df5.join(dummies5)\n",
    "newData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Which age group is the most frequent?\n",
    "print newData.Age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I want to drop the \"Age\" and \"16-30\" columns.\n",
    "newData.drop(newData[[\"Age\", \"Age_16-30\"]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining veriables for my new regession:\n",
    "x = newData[newData.columns[1:]]\n",
    "Y = newData[newData.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm2 = LogisticRegression()\n",
    "\n",
    "result2 = lm2.fit(x,Y)\n",
    "predictions2 = lm2.predict(x)\n",
    "print \"Score:\",result2.score(x,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To determine the coefficients for the correlations and the intercept:\n",
    "print result2.coef_\n",
    "print result2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To determine the p-value for each coefficient:\n",
    "from sklearn.feature_selection import chi2\n",
    "scores, pvalues = chi2(x, Y)\n",
    "pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To determine the odds for each coefficeient, I have to take the exponent of the coefficient.\n",
    "#The same goes for the intercept.\n",
    "print np.exp(result2.coef_)\n",
    "print np.exp(result2.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable|Coefficient|P-Value\n",
    "--|--|--\n",
    "SibSp|0.669|0.108\n",
    "Parch|0.814|0.001\n",
    "Fare|1.004|0.000\n",
    "female|13.406|0.000\n",
    "C|1.437|0.000\n",
    "Q|1.357|0.917\n",
    "Class_1|5.205|0.000\n",
    "Class_2|2.630|0.013\n",
    "Age_16 and under|5.323|0.000\n",
    "Age_31-45|1.176|0.220\n",
    "Age_46-60|0.688|0.536\n",
    "Age_61 and above|0.493|0.131\n",
    "Intercept|0.110|-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our results, we see SibSp, Q and all age groups except \"Age_16 and under\" statistically insignificant at a 5% significance level. For this model, our baseline is a male from Southhampton in the 3rd class between the ages of 16-30. Similar to the first model, SibSp and Parch generally decrease the odds of survival while Fare, Female, C, Q, Class_1, Class_2, and Age_16 and under generally increase the odds of survival. From this model, we find that only children 16 and under in the group had a signicantly higher chance of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, Y_train, Y_test = train_test_split(x, Y, train_size=0.70, random_state=15)\n",
    "\n",
    "lm3 = LogisticRegression()\n",
    "\n",
    "result3 = lm3.fit(x_train, Y_train)\n",
    "predictions3 = lm3.predict(x_test)\n",
    "print \"Score:\",result3.score(x_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pb = result3.predict_proba(x_test)\n",
    "x_test[\"ProbabilityOfZero\"] = pb[:,0]\n",
    "x_test[\"ProbabilityOfOne\"] = pb[:,1]\n",
    "x_test[\"actualSurvived\"] = Y_test\n",
    "x_test['predictedSurvived'] = result3.predict( x_test[ x_test.columns[0:12] ] )\n",
    "dFrame = x_test\n",
    "#dFrame['predictedSurvived'] = result3.predict( dFrame[ dFrame.columns[0:12] ] )\n",
    "dFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, Y_train, Y_test = cross_validation.train_test_split(x, Y, train_size=0.70, random_state=15)\n",
    "lm4 = LogisticRegression()\n",
    "\n",
    "result4 = lm4.fit(x_train,Y_train)\n",
    "predictions = lm4.predict(x_test)\n",
    "print \"Score:\", result4.score(x_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pd.crosstab(\n",
    "                    dFrame[\"actualSurvived\"],\n",
    "                    dFrame[\"predictedSurvived\"], \n",
    "                    rownames=[\"actual\"]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crosstab shows a confusion matric for the test set. The matrix shows the following:  \n",
    "\n",
    "TN|129\n",
    "--|-- \n",
    "FP|23\n",
    "FN|32\n",
    "TP|84\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target    = dFrame[\"actualSurvived\"].tolist()\n",
    "predicted = dFrame[\"predictedSurvived\"].tolist()\n",
    "target_names = [\"Not Survived\", \"Survived\"]\n",
    "\n",
    "print(classification_report(target, predicted, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precison (TP/TP+FP) shows retrieved instances that are relevant i.e. the proportion of people that actually survived from the total number people that our model predicted survived. Recall (TP/TP+FN) indicates the proportion of people that our model predicted survived from the total number of people that actually survived. The F1-score indicates how well it can predict the a pasenger surviving relative to predicting a apssenger not surviving. For this model, the precision, recall and F1-score are all 0.79."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print metrics.accuracy_score(Y_test, predictions3)\n",
    "print metrics.roc_auc_score(Y_test, pb[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analyses above, we can imply that people on the titanic were more likely to survive if they were female, aged 16 or below, and in the 1st class. These results were derived from certain assumptions what we need to review. For instance, we are assume the age of 177 passengers to be the average age of the remaining 714. We assumes the age of almost 20% of the passengers (this is a huge percentage relative to the dataset). Another problem is that we assume everyone was in their assigned class while the boat was sinking. It may have been the case that some people from the 1st class cabin (whose cabins were vertically further away from the ocean) were actually at the lower levels of the boat. I really don't see the 1st class passengers chilling at the lower level with the \"commoners\", but who's to say? Still from the data we collect, we are able to develop so insights aboue chances of survival. With our pretty decent precision and recall rate, we can apply out model to help manage situations in the event of a plane crash. Imagine a scenerio when a plane crash occured, and were are unable to find all the passengers and crew members. We can collect informtion from each passenger's boarding pass and driver's license/passport, we can use our modele to predict (to a good extent) the chance of survival. Obviously, certain other factors will have to be considered given that the disaster in a plane crash and not a ship sinking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
